#   Projeto normalização e padronização dos dados

Neste projeto vou mostrar como fazer NORMALIZAÇÃO e PADRONIZAÇÃO de dados com Python.

Vou falar de um tema muito importante quando criamos um modelo preditivo: a padronização dos dados. Mas afinal, a gente padroniza ou normaliza? Qual a diferença entre os dois? E por que isso é necessário?

Eu vou explicar os conceitos de normalização e padronização, como eles funcionam e, depois, vou criar modelos preditivos passo a passo, na prática e com todos os detalhes.

Uma coisa crucial ao montar um modelo de Machine Learning é a dimensão e a escala dos dados. Cada variável pode estar em uma escala diferente: algumas podem ser números inteiros, outras, números fracionados. Além disso, uma mesma variável pode ter valores em escalas completamente distintas—de dezenas a milhões—e isso impacta diretamente o resultado do nosso modelo.

Se a gente não fizer um pré-processamento adequado, o modelo até vai funcionar, mas a acurácia será prejudicada. Pior ainda: podemos enfrentar problemas como enviesamento (bias) e overfitting, simplesmente porque não tratamos os dados corretamente.

Por isso, normalizar e padronizar os dados é uma etapa essencial na criação de qualquer modelo preditivo, seja de Machine Learning ou Inteligência Artificial.

Neste projeto, vou mostrar tudo passo a passo, incluindo:

- As fórmulas e cálculos usados para medir distâncias (como a distância euclidiana) em algoritmos de Machine Learning.

- Como funcionam as fórmulas de padronização e normalização.

- Desvio padrão, média, mediana e distribuição normal.

Na parte prática, vou usar Python para aplicar esses conceitos, utilizando a biblioteca Scikit-Learn e seus métodos:

- MinMaxScaler (para normalização)

- StandardScaler (para padronização)

Além disso, vou criar modelos preditivos com algoritmos como KNN e SVM, tudo explicado detalhadamente.

